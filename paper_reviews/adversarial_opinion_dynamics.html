<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>Adversarial Perturbations of Opinion Dynamics in Networks</title>

    <meta name="description" content="Paper review and related literature review">
    <meta name="author" content="AlOrozco53">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="../../css/reveal.css">
    <link rel="stylesheet" href="../../css/theme/custom_white.css" id="theme">

    <!-- Footer -->
    <link rel="stylesheet" href="../../plugin/title-footer/title-footer.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="../../lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? '../../css/print/pdf.css' : '../../css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
	<!-- <section> -->
	<section data-menu-title="Title" data-background-image="../../img/nets.gif">
	  <h3>
	    <font color="white">
	      Adversarial Perturbations of Opinion Dynamics in Networks
	    </font>
	  </h3>
	  <font color="white">
	    <font size="4">
	      <i>
		Jason Gaitonde,
		Jon Kleinberg,
		Éva Tardos
	      </i>
	      <p>
	    </font>
	    <font size="3">
	      Cornell University
	      <p>
		2020
	    </font>
	    <p>
	    <font size="4">
	      presented by Albert M Orozco Camacho
	    </font>
	  </font>
	</section>
	<section data-menu-title="Motivation">
	  <section data-menu-title="Motivation" data-transition="fade">
	    <h1>Motivation</h1>
	  </section>
	  <section data-menu-title="Introduction" data-transition="fade">
	    <p class="fragment" data-fragment-index="1">
	      <b>Neighborhood aggregation</b> turns out to be a crucial part of representation
	      learning, due to the rise of <i>graph neural networks</i>.
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      Such procedure aims to extract high-level features from nodes via a
	      <i>message passing</i> scheme.
	    </p>
	    <aside class="notes">
	      What do aggregation methods bring to the table?
	      <p>
	      A generalization of a graph isomorphism test, enabling to learn the topology and
	      distribution of node features in the neighborhood.
	    </aside>
	  </section>
	  <section data-menu-title="Problems" data-transition="fade">
	    <h3>Caveats of Traditional Aggregation Schemes</h3>
	    <p class="fragment" data-fragment-index="1">
	      Usually, traditional GCNs show state-of-the-art performance only with a 2-layer model,
	      while deeper models don't take advantage of accessing to more information.
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      Networks that exhibit a diversity in subgraph structures (such as node hubs)
	      yield inconsistent learning of node relations by GCNs.
	    </p>
	    <aside class="notes">
	      Also, scale-free networks (ones that follow a power law distribution) may fail to be modeled.
	    </aside>
	  </section>
	  <section data-transition="fade" data-background-image="../../img/twitter-users.jpg">
	    <h2></h2>
	    <aside class="notes">
	      - Graphs in Social Media
	    </aside>
	  </section>
	  <section>
	    <h2>Neighborhood aggregation in GNNs</h2>
	    <img src="../../img/jumping-aggregation.png" width="80%" height="80%" alt="">
	  </section>
	  <section data-transition="fade" data-background-image="../../img/jumping-sn.png">
	    <h2>Changing Locality</h2>
	    <aside class="notes">
	      Of special interest for this paper is to analyze how the spread of influence between nodes
	      is related to random walk distributions, and hence, what this tells us about GNN learning.
	    </aside>
	  </section>
	  <section>
	    <h2>Influence distributions vs Random Walks</h2>
	    <img src="../../img/jumping-rw.png" width="80%" height="80%" alt="">
	    <aside class="notes">
	      Is it possible to adaptively adjust (learn) the influence radii for each node and task?
	    </aside>
	  </section>
	</section>
	<section data-menu-title="Definitions">
	  <section data-menu-title="Definitions" data-transition="fade">
	    <h1>Definitions</h1>
	  </section>
	  <section data-markdown data-separator-notes="Note:">
	    <textarea data-template>
	      ## Graph Neural Networks 
	      Consider a undirected graph $G = (V, E)$:
	      - $X_v \in \mathbb{R}^{d_i}$ is a vector of features per each $v \in V$;
	      - $\tilde{G}$ is the graph obtained by adding self-loops to each vertex;
	      - let $h_v^{(l)} \in \mathbb{R}^{d_h}$ is the hidden feature of node $v$
	      by the $l$-th layer of the model.

	      Note:
	      The dimension of the hidden layers is assumed to be the same accross layers.
	    </textarea>
	  </section>
	  <section>
	    <h3>Hidden Layer Update for a GNN</h3>
	    <font size="6">
	      $$
	      h_v^{(l)} = \sigma\left(W_l \cdot \text{AGGREGATE}\left(\{h_u^{(l-1)}, \forall u \in \tilde{N}(v)\}\right)\right)
	      $$
	    </font>
	  </section>
	  <section>
	    <h3>Graph Convolutional Neural Networks</h3>
	    <font size="6">
	      $$
	      h_v^{(l)} = \text{RELU}\left(W_l \cdot \sum_{u \in \tilde{N}(v)}(\deg(v)\deg(u))^{-\frac{1}{2}} h_u^{(l-1)}\right)
	      $$
	      <p>
	      <p>
	      $$
	      h_v^{(l)} = \text{RELU}\left(W_l \cdot \frac{1}{\tilde{\deg}(v)} \sum_{u \in \tilde{N}(v)} h_u^{(l-1)}\right)
	      $$
	    </font>
	    <aside class="notes">
	      The role of normalization in both equations determines how to rank nodes of higher degree.
	    </aside>
	  </section>
	  <section>
	    <h3>Neighborhood Aggregation with Skip Connections</h3>
	    <font size="6">
	      $$
	      h_{N(v)}^{(l)} = \sigma\left(W_l \cdot \text{AGGREGATE}_N\left(\{h_u^{(l-1)}, \forall u \in N(v)\}\right)\right)
	      $$
	      <p>
	      $$
	      h_v^{(l)} = \text{COMBINE}\left(h_v^{(l-1)}, h_{N(v)}^{(l)}\right)
	      $$
	    </font>
	    <aside class="notes">
	      AGGREGATE and COMBINE are defined by the specific model.
	      This model can be combined with GAT and GraphSAGE, for instance, to add representational power.
	      Those approaches are orthogonal to what is presented here.
	    </aside>
	  </section>
	  <section>
	    <h2>Influence Distributions</h2>
	    <font size="6">
	      $$
	      I_x(y) = \frac{e^T \left[\frac{\partial h_x^{(k)}}{\partial h_y^{(0)}} e\right]}{\sum_{z \in V} e^T \frac{\partial h_x^{(k)}}{\partial h_z^{(0)}} e}
	      $$
	    </font>
	    <p>
	      where $e$ is an all-ones vector
	      <aside class="notes">
		How does a change in the inpute of node $x$ affects the output of node $y$?
	      </aside>
	  </section>
	  <section data-markdown data-separator-notes="Note:">
	    <textarea data-template>
	      ## Model Analysis
	    </textarea>
	  </section>
	  <section data-markdown data-separator-notes="Note:">
	    <textarea data-template>
	      ### Theorem 1

	      Given a $k$-layer GCN with averaging by each node's degree at each hidden layer update,  assume that all paths in the computation graph of the model are activated with the same probability of
	      success $\rho$.

	      Then the influence distribution $I_x$ for any node $x \in V$ is equivalent,
	      in expectation, to the $k$-step random walk distribution on $G$ starting at node $x$.

	      Note:
	      Note there is no assumption on the structure of graph $G$, thus guaranteeing
	      the practical intention of this result for the sake of this paper.
	    </textarea>
	  </section>
	  <section data-markdown data-separator-notes="Note:">
	    <textarea data-template>
	      ### A Crucial Implication of Theorem 1

	      Information aggregation rate while updating hidden layers depends on the
	      local structure radius.

	      - Large radii may lead to too much averaging.
	      - Small radii may lead to in- stabilities or insufficient information aggregation.
	    </textarea>
	  </section>
	  <section data-transition="fade" data-background-image="../../img/jumping-influence.png">
	  </section>
	</section>
	<section data-menu-title="Adversarial Optimization">
	  <section data-menu-title="Adversarial Optimization" data-transition="fade">
	    <h1>Adversarial Optimization</h1>
	  </section>
	  <section data-menu-title="Architecture" data-transition="fade">
	    <h3>The proposed aggregation scheme... </h3>
	    <p>
	    <font size="6">
	      <p class="fragment" data-fragment-index="1">
		makes each layer increase the size of the influence distribution by aggregating
		neighborhoods from the previous layer ⬆️;
	      </p>
	      <p class="fragment" data-fragment-index="2">
		combines, at the last layer, some of the previous layers' representations
		independently for each node;
	      </p>
	      <p class="fragment" data-fragment-index="3">
		intermediate representations are said to <b><i>jump</i></b> to the last layer.
	      </p>
	    </font>
	  </section>
	  <section data-menu-title="Aggregation Mechanisms" data-transition="fade">
	    <h3>Aggregation Mechanisms</h3>
	    <p>
	    <font size="6">
	      <p class="fragment" data-fragment-index="1">
		<b>CONCATENATION</b>
		$$[h_v^{(1)},\ldots,h_v^{(k)}]$$
	      </p>
	      <p class="fragment" data-fragment-index="2">
		<b>MAX-POOLING</b>. Select the most informative layer for each feature coordinate.
	      </p>
	      <p class="fragment" data-fragment-index="3">
		<b>LSTM-ATTENTION</b>. Input $h_v^{(1)},\ldots,h_v^{(k)}$ into a bi-directional
		LSTM to generate forward and backward features $f_v^{(l)}$ and $b_v^{(l)}$ for each
		layer $l$; finally compute an attention score per each node by combining those
		for each layer.
	      </p>
	    </font>
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-architecture.png" width="50%" height="50%" alt="">
	  </section>
	  <section data-markdown  data-separator-notes="Note:">
	    <textarea data-template>
	      ## JK-Net learns to Adapt!
	    </textarea>
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-adapt.png" width="110%" height="110%" alt="">
	  </section>
	  <section>
	      <h3>Proposition 1</h3>
	      <font size="5">
		Assume that paths of the same length in the computation graph are activated with the same probability.
		<p>
		The influence score $I(x, y)$ for any $x, y \in V$ under a $k$-layer JK-Net with layer-wise max-pooling is equivalent
		in expectation to a mixture of $0,\ldots,k$-step random walk distributions on $\tilde{G}$ at $y$
		starting at $x$, the coefficients of which depend on the values of the layer features $h_x^{(l)}$.
	      </font>
	      <aside class="notes">
		There is no assumption on the structure of graph $G$!
	      </aside>
	  </section>
	</section>
	<section data-menu-title="Mixed Graph Objectives">
	  <section data-menu-title="Mixed Graph Objectives" data-transition="fade">
	    <h1>Mixed Graph Objectives</h1>
	  </section>
	  <section>
	    <h3>Datasets</h3>
	    <img src="../../img/reddit.png" width="40%" height="40%" alt="">
	    <img src="../../img/jumping-ppi.png" width="50%" height="50%" alt="">
	  </section>
	  <section data-markdown  data-separator-notes="Note:">
	    <textarea data-template>
	      ## Settings
	      
	      ![setup](../../img/jumping-dataset-stats.png)
	    </textarea>
	  </section>
	  <section data-markdown  data-separator-notes="Note:">
	    <textarea data-template>
	      ## Results
	      
	      Note:
	      Convergence is NOT guaranteed!
	    </textarea>
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-results-gcn-jk-cc.png" width="110%" height="110%" alt="">
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-results-graphsage-jk-reddit.png" width="110%" height="110%" alt="">
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-results-graphsage-jk-ppi.png" width="110%" height="110%" alt="">
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-microf1-gat-jk.png" width="110%" height="110%" alt="">
	  </section>
	</section>
	<section data-menu-title="Related Work">
	  <section data-menu-title="Related Work" data-transition="fade">
	    <h1>Related Work</h1>
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-meme.png" width="50%" height="50%" alt="">
	  </section>
	  <section data-menu-title="Conclusion" data-transition="fade">
	    <p class="fragment" data-fragment-index="1">
	      <b>Goal</b>: Provide a representation learning scheme that can generalize
	      better on diverse variety of network structure, than the one proposed for GCN's
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      <b>Problem</b>: Denser subgraphs may cause aggregation algorithms to converge
	      in expectation to biased random walks. ☹
	    </p>
	  </section>
	  <section>
	    <p class="fragment" data-fragment-index="4">
	      <b>Solution</b>: JK-Nets aggregate and leverage information from more than
	      one hidden layers.😁
	    </p>
	    <p class="fragment" data-fragment-index="5">
	      JK-Nets with the LSTM-attention aggregators outperform the non-adaptive
	      models GraphSAGE, GAT and JK-Nets with concatenation aggregators.
	    </p>
	    <font size="4">
	      <p class="fragment" data-fragment-index="6">
		<a href="https://github.com/ShinKyuY/Representation_Learning_on_Graphs_with_Jumping_Knowledge_Networks">
		  https://github.com/ShinKyuY/Representation_Learning_on_Graphs_with_Jumping_Knowledge_Networks
		</a>
	      </p>
	    </font>
	  </section>
	  <section data-menu-title="Future Work" data-transition="fade">
	    <h3>Future Work</h3>
	    <p class="fragment" data-fragment-index="1">
	      Exploring other layer aggregators and studying the effect of the combination of various
	      layer-wise and node-wise aggregators on different types of graph structures.
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      How can sequence modelling by itself impact the task of layer aggregation?
	    </p>
	    <p class="fragment" data-fragment-index="3">
	      Are there <i>smarter</i> ways to keep track of node/community correlations within a network?
	    </p>
	  </section>
	</section>
	<section data-menu-title="Conclusion">
	  <section data-menu-title="Conclusion" data-transition="fade">
	    <h1>Conclusion</h1>
	  </section>
	  <section data-transition="fade">
	    <img src="../../img/jumping-meme.png" width="50%" height="50%" alt="">
	  </section>
	  <section data-menu-title="Conclusion" data-transition="fade">
	    <p class="fragment" data-fragment-index="1">
	      <b>Goal</b>: Provide a representation learning scheme that can generalize
	      better on diverse variety of network structure, than the one proposed for GCN's
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      <b>Problem</b>: Denser subgraphs may cause aggregation algorithms to converge
	      in expectation to biased random walks. ☹
	    </p>
	  </section>
	  <section>
	    <p class="fragment" data-fragment-index="4">
	      <b>Solution</b>: JK-Nets aggregate and leverage information from more than
	      one hidden layers.😁
	    </p>
	    <p class="fragment" data-fragment-index="5">
	      JK-Nets with the LSTM-attention aggregators outperform the non-adaptive
	      models GraphSAGE, GAT and JK-Nets with concatenation aggregators.
	    </p>
	    <font size="4">
	      <p class="fragment" data-fragment-index="6">
		<a href="https://github.com/ShinKyuY/Representation_Learning_on_Graphs_with_Jumping_Knowledge_Networks">
		  https://github.com/ShinKyuY/Representation_Learning_on_Graphs_with_Jumping_Knowledge_Networks
		</a>
	      </p>
	    </font>
	  </section>
	  <section data-menu-title="Future Work" data-transition="fade">
	    <h3>Future Work</h3>
	    <p class="fragment" data-fragment-index="1">
	      Exploring other layer aggregators and studying the effect of the combination of various
	      layer-wise and node-wise aggregators on different types of graph structures.
	    </p>
	    <p class="fragment" data-fragment-index="2">
	      How can sequence modelling by itself impact the task of layer aggregation?
	    </p>
	    <p class="fragment" data-fragment-index="3">
	      Are there <i>smarter</i> ways to keep track of node/community correlations within a network?
	    </p>
	  </section>
	</section>
	<!-- <section data-menu-title="Backup Slides"> -->
	<!--   <section> -->
	<!--     <h1>Sketches of Proofs</h1> -->
	<!--   </section> -->
	<!-- </section> -->
	<section data-transition="fade">
	  <h2>Thank you!</h2>
	</section>

      </div>

    </div>

    <script src="../../lib/js/head.min.js"></script>
    <script src="../../js/reveal.js"></script>

    <script>

      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,

      transition: 'slide', // none/fade/slide/convex/concave/zoom

      math: {
      mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
      config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
      },

      // More info https://github.com/hakimel/reveal.js#dependencies
      dependencies: [
      { src: '../../lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: '../../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: '../../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: '../../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: '../../plugin/zoom-js/zoom.js', async: true },
      { src: '../../plugin/notes/notes.js', async: true },
      { src: '../../plugin/math/math.js', async: true },
      { src: '../../plugin/menu/menu.js' },
      { src: '../../plugin/title-footer/title-footer.js', async: true, callback: function() { title_footer.initialize(); } }
      ],

      keyboard: {
      67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle notes canvas when 'c' is pressed
      66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
      46: function() { RevealChalkboard.clear() },	// clear chalkboard when 'DEL' is pressed
      8: function() { RevealChalkboard.reset() },	// reset chalkboard data on current slide when 'BACKSPACE' is pressed
      68: function() { RevealChalkboard.download() },	// downlad recorded chalkboard drawing when 'd' is pressed
      },

      //menu
      menu: {
      // Specifies which side of the presentation the menu will
      // be shown. Use 'left' or 'right'.
      side: 'left',

      // Add slide numbers to the titles in the slide list.
      // Use 'true' or format string (same as reveal.js slide numbers)
      numbers: false,

      // Specifies which slide elements will be used for generating
      // the slide titles in the menu. The default selects the first
      // heading element found in the slide, but you can specify any
      // valid css selector and the text from the first matching
      // element will be used.
      // Note: that a section data-menu-title attribute or an element
      // with a menu-title class will take precedence over this option
      titleSelector: 'h1, h2, h3, h4, h5, h6',

      // Hide slides from the menu that do not have a title.
      // Set to 'true' to only list slides with titles.
      hideMissingTitles: false,

      // Add markers to the slide titles to indicate the
      // progress through the presentation
      markers: false,

      // Specify custom panels to be included in the menu, by
      // providing an array of objects with 'title', 'icon'
      // properties, and either a 'src' or 'content' property.
      custom: false,

      // Specifies the themes that will be available in the themes
      // menu panel. Set to 'false' to hide themes panel.
      themes: [
      { name: 'Black', theme: '../../css/theme/black.css' },
      { name: 'White', theme: '../../css/theme/white.css' },
      { name: 'League', theme: '../../css/theme/league.css' },
      { name: 'Sky', theme: '../../css/theme/sky.css' },
      { name: 'Beige', theme: '../../css/theme/beige.css' },
      { name: 'Simple', theme: '../../css/theme/simple.css' },
      { name: 'Serif', theme: '../../css/theme/serif.css' },
      { name: 'Blood', theme: '../../css/theme/blood.css' },
      { name: 'Night', theme: '../../css/theme/night.css' },
      { name: 'Moon', theme: '../../css/theme/moon.css' },
      { name: 'Solarized', theme: '../../css/theme/solarized.css' }
      ],

      // Specifies if the transitions menu panel will be shown.
      transitions: true,

      // Adds a menu button to the slides to open the menu panel.
      // Set to 'false' to hide the button.
      openButton: true,

      // If 'true' allows the slide number in the presentation to
      // open the menu panel. The reveal.js slideNumber option must
      // be displayed for this to take effect
      openSlideNumber: false,

      // If true allows the user to open and navigate the menu using
      // the keyboard. Standard keyboard interaction with reveal
      // will be disabled while the menu is open.
      keyboard: true
      }

      });

    </script>

    <style type="text/css">
      /* 1. Style header/footer <div> so they are positioned as desired. */
	#header-left {
        position: absolute;
        top: 0%;
        left: 0%;
	}
	#header-right {
        position: absolute;
        top: 0%;
        right: 0%;
	}
	#footer-left {
        position: absolute;
        bottom: 5%;
        left: 43%;
	}
    </style>

    <!-- 2. Create hidden header/footer <div> -->
    <div id="hidden" style="display:none;">
      <div id="header">
        <!-- <div id="header-left">HEADER-LEFT</div> -->
        <!-- <div id="header-right">HEADER-RIGHT</div> -->
      </div>
    </div>

    <script src="https://code.jquery.com/jquery-2.2.4.min.js"></script>
    <script type="text/javascript">
      // 3. On Reveal.js ready event, copy header/footer <div> into each `.slide-background` <div>
	  var header = $('#header').html();
	  if ( window.location.search.match( /print-pdf/gi ) ) {
          Reveal.addEventListener( 'ready', function( event ) {
          $('.slide-background').append(header);
          });
	  }
	  else {
          $('div.reveal').append(header);
	  }
    </script>

  </body>
</html>
